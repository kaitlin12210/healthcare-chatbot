{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.11",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Agents Lab Notebook v1.0.0\n",
        "This notebook contains steps and code to demonstrate the use of agents\n",
        "configured in Agent Lab in watsonx.ai. It introduces Python API commands\n",
        "for authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n",
        "\n",
        "**Note:** Notebook code generated using Agent Lab will execute successfully.\n",
        "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
        "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "## Notebook goals\n",
        "The learning goals of this notebook are:\n",
        "\n",
        "* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n",
        "* Creating an agent with a set of tools using a specified model and parameters\n",
        "* Invoking the agent to generate a response\n",
        "\n",
        "# Setup"
      ],
      "metadata": {
        "id": "SFYaC-VOOPwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from langchain_ibm import ChatWatsonx\n",
        "from ibm_watsonx_ai import APIClient\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
        "import json\n",
        "import requests"
      ],
      "metadata": {
        "id": "b5f8c4b7-e692-476e-8d97-84a41f0e8f6e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph"
      ],
      "metadata": {
        "id": "SDAPxpBcPvqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab8e204-8ce3-459f-c5d7-828b3fd7a294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn"
      ],
      "metadata": {
        "id": "L0dfOqsOOqmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4711e25-4a41-4827-b8c5-e250e652726c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## watsonx API connection\n",
        "This cell defines the credentials required to work with watsonx API for Foundation\n",
        "Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
        "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
      ],
      "metadata": {
        "id": "auqizGYQOPwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-ibm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf4DhDO9PVj_",
        "outputId": "3e620106-1117-43a2-bb01-dfdbad45c12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-ibm\n",
            "  Downloading langchain_ibm-1.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-ibm) (1.0.3)\n",
            "Collecting ibm-watsonx-ai<2.0.0,>=1.3.37 (from langchain-ibm)\n",
            "  Downloading ibm_watsonx_ai-1.4.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (2.32.4)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (2.5.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in /usr/local/lib/python3.12/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (2.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (2025.10.5)\n",
            "Collecting lomond (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm)\n",
            "  Downloading lomond-0.3.3-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (25.0)\n",
            "Collecting ibm-cos-sdk<2.15.0,>=2.12.0 (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm)\n",
            "  Downloading ibm_cos_sdk-2.14.3.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (5.5.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ibm) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ibm) (0.4.38)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ibm) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ibm) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ibm) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ibm) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (0.16.0)\n",
            "Collecting ibm-cos-sdk-core==2.14.3 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm)\n",
            "  Downloading ibm_cos_sdk_core-2.14.3.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cos-sdk-s3transfer==2.14.3 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm)\n",
            "  Downloading ibm_cos_sdk_s3transfer-2.14.3.tar.gz (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<=1.0.1,>=0.10.0 (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from ibm-cos-sdk-core==2.14.3->ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (2.9.0.post0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-ibm) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ibm) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ibm) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ibm) (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ibm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ibm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ibm) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (3.4.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai<2.0.0,>=1.3.37->langchain-ibm) (1.3.1)\n",
            "Downloading langchain_ibm-1.0.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_watsonx_ai-1.4.5-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
            "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.14.3-py3-none-any.whl size=77232 sha256=116b683c62ba3887d90c1844c91eab093db944625f16eef919bce6a3c2b1c128\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/2f/6f/125918ad46d280d3bea58edf99f0757888ef6e7999db4b73b7\n",
            "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.14.3-py3-none-any.whl size=662101 sha256=3a5db23f39c6f0608586bb6456f8075ffba015f881ccd7cf7c2dc5614d5c769a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/53/13/7c8fdeebdb847995d8ef349b4f695c595d8d31b30ae2a07ea2\n",
            "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.14.3-py3-none-any.whl size=90203 sha256=a6d1b770eb429e22f0a5dba91685513ad80a02dbf8dd0aba5c960b97755d680d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/8b/10/0346c5a955b48b7fca50a8a42de309546b22899b7e8c1da8a5\n",
            "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
            "Installing collected packages: lomond, jmespath, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, ibm-watsonx-ai, langchain-ibm\n",
            "Successfully installed ibm-cos-sdk-2.14.3 ibm-cos-sdk-core-2.14.3 ibm-cos-sdk-s3transfer-2.14.3 ibm-watsonx-ai-1.4.5 jmespath-1.0.1 langchain-ibm-1.0.0 lomond-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "def get_credentials():\n",
        "\treturn {\n",
        "\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n",
        "\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n",
        "\t}\n",
        "\n",
        "def get_bearer_token():\n",
        "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
        "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n",
        "\n",
        "    response = requests.post(url, headers=headers, data=data)\n",
        "    return response.json().get(\"access_token\")\n",
        "\n",
        "credentials = get_credentials()"
      ],
      "metadata": {
        "id": "95a50c29-8a6e-4422-8461-9ab5466f0ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0f3727-c6d3-44ef-ba44-fc8e13f7c34b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your api key (hit enter): ··········\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the agent\n",
        "These cells demonstrate how to create and invoke the agent\n",
        "with the selected models, tools, and parameters.\n",
        "\n",
        "## Defining the model id\n",
        "We need to specify model id that will be used for inferencing:"
      ],
      "metadata": {
        "id": "uktU0DJ9OPwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/llama-3-3-70b-instruct\""
      ],
      "metadata": {
        "id": "be2bb191-f4a7-4301-b3fc-e33d02544630"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the\n",
        "result:"
      ],
      "metadata": {
        "id": "LFB9FwIyOPwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"frequency_penalty\": 0,\n",
        "    \"max_tokens\": 2000,\n",
        "    \"presence_penalty\": 0,\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1\n",
        "}"
      ],
      "metadata": {
        "id": "5b4b3100-a5c0-4c04-a833-cd5f328761bc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the project id or space id\n",
        "The API requires project id or space id that provides the context for the call. We will obtain\n",
        "the id from the project or space in which this notebook runs:"
      ],
      "metadata": {
        "id": "KkFHkrd2OPwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = os.getenv(\"PROJECT_ID\")\n",
        "space_id = os.getenv(\"SPACE_ID\")\n"
      ],
      "metadata": {
        "id": "fe144ab4-bfd1-4902-94d7-e56c9f51a1d1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the agent\n",
        "We need to create the agent using the properties we defined so far:"
      ],
      "metadata": {
        "id": "nvPAvUNzOPwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n",
        "\n",
        "# Create the chat model\n",
        "def create_chat_model():\n",
        "    chat_model = ChatWatsonx(\n",
        "        model_id=model_id,\n",
        "        url=credentials[\"url\"],\n",
        "        space_id=space_id,\n",
        "        project_id=project_id,\n",
        "        params=parameters,\n",
        "        watsonx_client=client,\n",
        "    )\n",
        "    return chat_model"
      ],
      "metadata": {
        "id": "e777dc7a-83d1-4811-896e-b2b5774535d5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "\n",
        "\n",
        "vector_index_id = \"8052405a-0dad-4ab0-bf29-bb28d1b116fb\"\n",
        "\n",
        "def create_rag_tool(vector_index_id, api_client):\n",
        "    config = {\n",
        "        \"vectorIndexId\": vector_index_id,\n",
        "        \"projectId\": project_id\n",
        "    }\n",
        "\n",
        "    tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about healthcare_dataset_PDF\"\n",
        "\n",
        "    return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n",
        "\n",
        "\n",
        "\n",
        "def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n",
        "    from langchain_core.tools import StructuredTool\n",
        "    utility_agent_tool = Toolkit(\n",
        "        api_client=api_client\n",
        "    ).get_tool(tool_name)\n",
        "\n",
        "    tool_description = utility_agent_tool.get(\"description\")\n",
        "\n",
        "    if (kwargs.get(\"tool_description\")):\n",
        "        tool_description = kwargs.get(\"tool_description\")\n",
        "    elif (utility_agent_tool.get(\"agent_description\")):\n",
        "        tool_description = utility_agent_tool.get(\"agent_description\")\n",
        "\n",
        "    tool_schema = utility_agent_tool.get(\"input_schema\")\n",
        "    if (tool_schema == None):\n",
        "        tool_schema = {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "            \"properties\": {\n",
        "                \"input\": {\n",
        "                    \"description\": \"input for the tool\",\n",
        "                    \"type\": \"string\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def run_tool(**tool_input):\n",
        "        query = tool_input\n",
        "        if (utility_agent_tool.get(\"input_schema\") == None):\n",
        "            query = tool_input.get(\"input\")\n",
        "\n",
        "        results = utility_agent_tool.run(\n",
        "            input=query,\n",
        "            config=params\n",
        "        )\n",
        "\n",
        "        return results.get(\"output\")\n",
        "\n",
        "    return StructuredTool(\n",
        "        name=tool_name,\n",
        "        description = tool_description,\n",
        "        func=run_tool,\n",
        "        args_schema=tool_schema\n",
        "    )\n",
        "\n",
        "\n",
        "def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n",
        "    from langchain_core.tools import StructuredTool\n",
        "    import ast\n",
        "\n",
        "    def call_tool(**kwargs):\n",
        "        tree = ast.parse(tool_code, mode=\"exec\")\n",
        "        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n",
        "        function_name = custom_tool_functions[0].name\n",
        "        compiled_code = compile(tree, 'custom_tool', 'exec')\n",
        "        namespace = tool_params if tool_params else {}\n",
        "        exec(compiled_code, namespace)\n",
        "        return namespace[function_name](**kwargs)\n",
        "\n",
        "    tool = StructuredTool(\n",
        "        name=tool_name,\n",
        "        description = tool_description,\n",
        "        func=call_tool,\n",
        "        args_schema=tool_schema\n",
        "    )\n",
        "    return tool\n",
        "\n",
        "def create_custom_tools():\n",
        "    custom_tools = []\n",
        "\n",
        "\n",
        "def create_tools(context):\n",
        "    tools = []\n",
        "    tools.append(create_rag_tool(vector_index_id, client))\n",
        "\n",
        "    config = None\n",
        "    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n",
        "    config = {\n",
        "        \"maxResults\": 5\n",
        "    }\n",
        "    tools.append(create_utility_agent_tool(\"Wikipedia\", config, client))\n",
        "\n",
        "    return tools"
      ],
      "metadata": {
        "id": "0352c7ab-c6c0-4c09-8522-494be85198b6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_agent(context):\n",
        "    # Initialize the agent\n",
        "    chat_model = create_chat_model()\n",
        "    tools = create_tools(context)\n",
        "\n",
        "    memory = MemorySaver()\n",
        "    instructions = \"\"\"# Notes\n",
        "- Use markdown syntax for formatting code snippets, links, JSON, tables, images, files.\n",
        "- Any HTML tags must be wrapped in block quotes, for example ```<html>```.\n",
        "- When returning code blocks, specify language.\n",
        "- Sometimes, things don't go as planned. Tools may not provide useful information on the first few tries. You should always try a few different approaches before declaring the problem unsolvable.\n",
        "- When the tool doesn't give you what you were asking for, you must either use another tool or a different tool input.\n",
        "- When using search engines, you try different formulations of the query, possibly even in a different language.\n",
        "- You cannot do complex calculations, computations, or data manipulations without using tools.\n",
        "- If you need to call a tool to compute something, always call it instead of saying you will call it.\n",
        "\n",
        "If a tool returns an IMAGE in the result, you must include it in your answer as Markdown.\n",
        "\n",
        "Example:\n",
        "\n",
        "Tool result: IMAGE({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\n",
        "Markdown to return to user: ![Generated image]({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\n",
        "\n",
        "You are a Preventative Healthcare Health Assistant/Chatbot, designed to help users stay healthy through personalized wellness guidance and education. Provide information on healthy lifestyle habits, routine screenings, vaccinations, nutrition, physical activity, stress management, and sleep hygiene. Use evidence-based recommendations from reputable health organizations, and/or provided PDFs if uploaded, and/or provided datasets. Encourage proactive health behaviors and early detection while maintaining a supportive, friendly, and non-judgmental tone. Clarify that you are not a substitute for professional medical advice, diagnosis, or treatment, and always encourage users to consult a healthcare provider for specific concerns. Tailor responses to user goals, age group, lifestyle, risk factors, and general wellness needs. You are privacy-preserving and able to work multilingually and accessibly. Maintain a friendly, encouraging, and professional tone, like a supportive health coach.\"\"\"\n",
        "\n",
        "    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n",
        "\n",
        "    return agent"
      ],
      "metadata": {
        "id": "fe684d05-463a-4d1a-9874-042e15106727"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the graph\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "Image(\n",
        "    create_agent(context).get_graph().draw_mermaid_png(\n",
        "        draw_method=MermaidDrawMethod.API,\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "c6d7471f-0533-4c6c-88ed-c1c718210dc7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Invoking the agent\n",
        "Let us now use the created agent, pair it with the input, and generate the response to your question:\n"
      ],
      "metadata": {
        "id": "65ihwQK5OPwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_agent(context)\n",
        "\n",
        "def convert_messages(messages):\n",
        "    converted_messages = []\n",
        "    for message in messages:\n",
        "        if (message[\"role\"] == \"user\"):\n",
        "            converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
        "        elif (message[\"role\"] == \"assistant\"):\n",
        "            converted_messages.append(AIMessage(content=message[\"content\"]))\n",
        "    return converted_messages\n",
        "\n",
        "question = input(\"Question: \")\n",
        "\n",
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": question\n",
        "}]\n",
        "\n",
        "generated_response = agent.invoke(\n",
        "    { \"messages\": convert_messages(messages) },\n",
        "    { \"configurable\": { \"thread_id\": \"42\" } }\n",
        ")\n",
        "\n",
        "print_full_response = False\n",
        "\n",
        "if (print_full_response):\n",
        "    print(generated_response)\n",
        "else:\n",
        "    result = generated_response[\"messages\"][-1].content\n",
        "    print(f\"Agent: {result}\")\n"
      ],
      "metadata": {
        "id": "3115599d-de7e-4aad-96c3-eb05c6dc5e9a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next steps\n",
        "You successfully completed this notebook! You learned how to use\n",
        "watsonx.ai inferencing SDK to generate response from the foundation model\n",
        "based on the provided input, model id and model parameters. Check out the\n",
        "official watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n",
        "\n",
        "<a id=\"copyrights\"></a>\n",
        "### Copyrights\n",
        "\n",
        "Licensed Materials - Copyright © 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
        "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
        "\n",
        "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
        "\n",
        "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "
      ],
      "metadata": {
        "id": "5xKZ0gaSOPwF"
      }
    }
  ]
}